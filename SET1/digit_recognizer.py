# -*- coding: utf-8 -*-
"""Digit_Recognizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16FS3m2g6dh1Q-dBwM80V8E4z6laNXJ3k

Importing important function from libraries
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
from keras.utils import np_utils
import matplotlib.pyplot as plt
import pandas as pd
import math

"""Training Data with 42000 images of 28*28 = 784 pixels each"""

train = pd.read_csv("/content/drive/MyDrive/Digit_Recognizer/train.csv")
print(train.shape)

"""Test Data with 28000 images of 28*28=784 pixels each"""

test = pd.read_csv("/content/drive/MyDrive/Digit_Recognizer/test.csv")
print(test.shape)

"""x_train is the input training data

y_train is the label/output of each input training image

x_test is the input test data
"""

x_train = train.iloc[:, 1:785].values
y_train = train.iloc[:, 0].values
x_test = test.iloc[:, 0:784].values
print(x_train.shape)
print(y_train.shape)

"""Dividing the images by 255 to normalize them"""

seed = 5
np.random.seed(seed)
x_train = x_train/255.0
x_test = x_test/255.0
print(x_train.shape)

"""We want images in a 28*28 size array"""

x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
print(x_train.shape)

"""Defining some constants"""

num_classes = 10          #We can have 10 different ouptuts
batch_size = 64           
epochs = 40               
input_shape = (28,28,1)   #Size of input image

"""Categorizing all outputs in 10 different possibilities"""

y_train = to_categorical(y_train, num_classes)
print(y_train.shape)

from sklearn.model_selection import train_test_split
x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.2, random_state=seed)

"""**MODEL**"""

model = Sequential()
model.add(Conv2D(32, kernel_size = (3,3), input_shape= input_shape, activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.2))
model.add(Conv2D(32, (3,3), activation = 'relu'))
model.add(MaxPooling2D())
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(512,activation = 'relu'))
model.add(Dense(512, activation = 'relu'))
model.add(Dense(num_classes, activation = 'sigmoid'))

model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

model.summary()

model.fit(x_train, y_train, epochs = epochs, verbose = 1)

loss , accuracy = model.evaluate(x_validation, y_validation, verbose = 0)
print("Loss : ",loss, "Accuracy : ", accuracy)

"""So, we got an accuracy of 98.88 percent and a loss of 0.7 % which is alright"""

predicted_classes = model.predict_classes(x_test)

submissions=pd.DataFrame({"ImageId": list(range(1,len(predicted_classes)+1)), "Label": predicted_classes})

submissions.to_csv("submission.csv", index = False, header = True)

from google.colab import files
files.download('submission.csv')

